{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c864a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pickle\n",
    "import unidecode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "from glob import glob\n",
    "from math import ceil\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec622db",
   "metadata": {},
   "source": [
    "### Getting Data Straight From S3 (PySpark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5151b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_pred = ['author_1','author_2','inst_match', 'inst_sum','concepts_shortest_match','concepts_shortest_sum',\n",
    "                 'concepts_shorter_match','concepts_shorter_sum','concepts_match','concepts_sum',\n",
    "              'coauthors_shorter_match','coauthors_shorter_sum','coauthors_match','coauthors_sum',\n",
    "                 'citation_match','citation_sum','citation_work_match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43de3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_either_work_show_in_citations(paper_id_1, paper_id_2, citation_1, citation_2):\n",
    "    if paper_id_1 in citation_2:\n",
    "        return 1\n",
    "    elif paper_id_2 in citation_1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b76f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_name_for_search(name):\n",
    "    name = unidecode.unidecode(unicodedata.normalize('NFKC', name))\n",
    "    name = name.lower().replace(\" \", \" \").replace(\".\", \" \").replace(\",\", \" \").replace(\"|\", \" \").replace(\")\", \"\").replace(\"(\", \"\")\\\n",
    "        .replace(\"-\", \"\").replace(\"&\", \"\").replace(\"$\", \"\").replace(\"#\", \"\").replace(\"@\", \"\").replace(\"%\", \"\").replace(\"0\", \"\") \\\n",
    "        .replace(\"1\", \"\").replace(\"2\", \"\").replace(\"3\", \"\").replace(\"4\", \"\").replace(\"5\", \"\").replace(\"6\", \"\").replace(\"7\", \"\") \\\n",
    "        .replace(\"8\", \"\").replace(\"9\", \"\").replace(\"*\", \"\").replace(\"^\", \"\").replace(\"{\", \"\").replace(\"}\", \"\").replace(\"+\", \"\") \\\n",
    "        .replace(\"=\", \"\").replace(\"_\", \"\").replace(\"~\", \"\").replace(\"`\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"\\\\\", \"\") \\\n",
    "        .replace(\"<\", \"\").replace(\">\", \"\").replace(\"?\", \"\").replace(\"/\", \"\").replace(\";\", \"\").replace(\":\", \"\").replace(\"\\'\", \"\") \\\n",
    "        .replace(\"\\\"\", \"\")\n",
    "    name = \" \".join(name.split())\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7036091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_match_list(name):\n",
    "    name_split_1 = name.replace(\"-\", \"\").split()\n",
    "    name_split_2 = \"\"\n",
    "    if \"-\" in name:\n",
    "        name_split_2 = name.replace(\"-\", \" \").split()\n",
    "\n",
    "    fn = []\n",
    "    fni = []\n",
    "    \n",
    "    m1 = []\n",
    "    m1i = []\n",
    "    m2 = []\n",
    "    m2i = []\n",
    "    m3 = []\n",
    "    m3i = []\n",
    "    m4 = []\n",
    "    m4i = []\n",
    "    m5 = []\n",
    "    m5i = []\n",
    "\n",
    "    ln = []\n",
    "    lni = []\n",
    "    for name_split in [name_split_1, name_split_2]:\n",
    "        if len(name_split) == 0:\n",
    "            pass\n",
    "        elif len(name_split) == 1:\n",
    "            if len(name_split[0]) > 1:\n",
    "                fn.append(name_split[0])\n",
    "                fni.append(name_split[0][0])\n",
    "            else:\n",
    "                fni.append(name_split[0][0])\n",
    "\n",
    "            if len(name_split[0]) > 1:\n",
    "                ln.append(name_split[0])\n",
    "                lni.append(name_split[0][0])\n",
    "            else:\n",
    "                lni.append(name_split[0][0])\n",
    "            \n",
    "        elif len(name_split) == 2:\n",
    "            if len(name_split[0]) > 1:\n",
    "                fn.append(name_split[0])\n",
    "                fni.append(name_split[0][0])\n",
    "            else:\n",
    "                fni.append(name_split[0][0])\n",
    "\n",
    "            if len(name_split[-1]) > 1:\n",
    "                ln.append(name_split[-1])\n",
    "                lni.append(name_split[-1][0])\n",
    "            else:\n",
    "                lni.append(name_split[-1][0])\n",
    "        elif len(name_split) == 3:\n",
    "            if len(name_split[0]) > 1:\n",
    "                fn.append(name_split[0])\n",
    "                fni.append(name_split[0][0])\n",
    "            else:\n",
    "                fni.append(name_split[0][0])\n",
    "\n",
    "            if len(name_split[1]) > 1:\n",
    "                m1.append(name_split[1])\n",
    "                m1i.append(name_split[1][0])\n",
    "            else:\n",
    "                m1i.append(name_split[1][0])\n",
    "\n",
    "            if len(name_split[-1]) > 1:\n",
    "                ln.append(name_split[-1])\n",
    "                lni.append(name_split[-1][0])\n",
    "            else:\n",
    "                lni.append(name_split[-1][0])\n",
    "        elif len(name_split) == 4:\n",
    "            if len(name_split[0]) > 1:\n",
    "                fn.append(name_split[0])\n",
    "                fni.append(name_split[0][0])\n",
    "            else:\n",
    "                fni.append(name_split[0][0])\n",
    "\n",
    "            if len(name_split[1]) > 1:\n",
    "                m1.append(name_split[1])\n",
    "                m1i.append(name_split[1][0])\n",
    "            else:\n",
    "                m1i.append(name_split[1][0])\n",
    "\n",
    "            if len(name_split[2]) > 1:\n",
    "                m2.append(name_split[2])\n",
    "                m2i.append(name_split[2][0])\n",
    "            else:\n",
    "                m2i.append(name_split[2][0])\n",
    "\n",
    "            if len(name_split[-1]) > 1:\n",
    "                ln.append(name_split[-1])\n",
    "                lni.append(name_split[-1][0])\n",
    "            else:\n",
    "                lni.append(name_split[-1][0])\n",
    "        elif len(name_split) == 5:\n",
    "            if len(name_split[0]) > 1:\n",
    "                fn.append(name_split[0])\n",
    "                fni.append(name_split[0][0])\n",
    "            else:\n",
    "                fni.append(name_split[0][0])\n",
    "\n",
    "            if len(name_split[1]) > 1:\n",
    "                m1.append(name_split[1])\n",
    "                m1i.append(name_split[1][0])\n",
    "            else:\n",
    "                m1i.append(name_split[1][0])\n",
    "\n",
    "            if len(name_split[2]) > 1:\n",
    "                m2.append(name_split[2])\n",
    "                m2i.append(name_split[2][0])\n",
    "            else:\n",
    "                m2i.append(name_split[2][0])\n",
    "                \n",
    "            if len(name_split[3]) > 1:\n",
    "                m3.append(name_split[3])\n",
    "                m3i.append(name_split[3][0])\n",
    "            else:\n",
    "                m3i.append(name_split[3][0])\n",
    "\n",
    "            if len(name_split[-1]) > 1:\n",
    "                ln.append(name_split[-1])\n",
    "                lni.append(name_split[-1][0])\n",
    "            else:\n",
    "                lni.append(name_split[-1][0])\n",
    "        elif len(name_split) == 6:\n",
    "            if len(name_split[0]) > 1:\n",
    "                fn.append(name_split[0])\n",
    "                fni.append(name_split[0][0])\n",
    "            else:\n",
    "                fni.append(name_split[0][0])\n",
    "\n",
    "            if len(name_split[1]) > 1:\n",
    "                m1.append(name_split[1])\n",
    "                m1i.append(name_split[1][0])\n",
    "            else:\n",
    "                m1i.append(name_split[1][0])\n",
    "\n",
    "            if len(name_split[2]) > 1:\n",
    "                m2.append(name_split[2])\n",
    "                m2i.append(name_split[2][0])\n",
    "            else:\n",
    "                m2i.append(name_split[2][0])\n",
    "\n",
    "            if len(name_split[3]) > 1:\n",
    "                m3.append(name_split[3])\n",
    "                m3i.append(name_split[3][0])\n",
    "            else:\n",
    "                m3i.append(name_split[3][0])\n",
    "            \n",
    "            if len(name_split[4]) > 1:\n",
    "                m4.append(name_split[4])\n",
    "                m4i.append(name_split[4][0])\n",
    "            else:\n",
    "                m4i.append(name_split[4][0])\n",
    "\n",
    "            if len(name_split[-1]) > 1:\n",
    "                ln.append(name_split[-1])\n",
    "                lni.append(name_split[-1][0])\n",
    "            else:\n",
    "                lni.append(name_split[-1][0])\n",
    "        elif len(name_split) == 7:\n",
    "            if len(name_split[0]) > 1:\n",
    "                fn.append(name_split[0])\n",
    "                fni.append(name_split[0][0])\n",
    "            else:\n",
    "                fni.append(name_split[0][0])\n",
    "\n",
    "            if len(name_split[1]) > 1:\n",
    "                m1.append(name_split[1])\n",
    "                m1i.append(name_split[1][0])\n",
    "            else:\n",
    "                m1i.append(name_split[1][0])\n",
    "\n",
    "            if len(name_split[2]) > 1:\n",
    "                m2.append(name_split[2])\n",
    "                m2i.append(name_split[2][0])\n",
    "            else:\n",
    "                m2i.append(name_split[2][0])\n",
    "\n",
    "            if len(name_split[3]) > 1:\n",
    "                m3.append(name_split[3])\n",
    "                m3i.append(name_split[3][0])\n",
    "            else:\n",
    "                m3i.append(name_split[3][0])\n",
    "            \n",
    "            if len(name_split[4]) > 1:\n",
    "                m4.append(name_split[4])\n",
    "                m4i.append(name_split[4][0])\n",
    "            else:\n",
    "                m4i.append(name_split[4][0])\n",
    "\n",
    "            if len(name_split[5]) > 1:\n",
    "                m5.append(name_split[5])\n",
    "                m5i.append(name_split[5][0])\n",
    "            else:\n",
    "                m5i.append(name_split[5][0])\n",
    "\n",
    "            if len(name_split[-1]) > 1:\n",
    "                ln.append(name_split[-1])\n",
    "                lni.append(name_split[-1][0])\n",
    "            else:\n",
    "                lni.append(name_split[-1][0])\n",
    "        else:\n",
    "            if len(name_split[0]) > 1:\n",
    "                fn.append(name_split[0])\n",
    "                fni.append(name_split[0][0])\n",
    "            else:\n",
    "                fni.append(name_split[0][0])\n",
    "\n",
    "            if len(name_split[1]) > 1:\n",
    "                m1.append(name_split[1])\n",
    "                m1i.append(name_split[1][0])\n",
    "            else:\n",
    "                m1i.append(name_split[1][0])\n",
    "\n",
    "            if len(name_split[2]) > 1:\n",
    "                m2.append(name_split[2])\n",
    "                m2i.append(name_split[2][0])\n",
    "            else:\n",
    "                m2i.append(name_split[2][0])\n",
    "\n",
    "            if len(name_split[3]) > 1:\n",
    "                m3.append(name_split[3])\n",
    "                m3i.append(name_split[3][0])\n",
    "            else:\n",
    "                m3i.append(name_split[3][0])\n",
    "                \n",
    "            if len(name_split[4]) > 1:\n",
    "                m4.append(name_split[4])\n",
    "                m4i.append(name_split[4][0])\n",
    "            else:\n",
    "                m4i.append(name_split[4][0])\n",
    "\n",
    "            joined_names = \" \".join(name_split[5:-1])\n",
    "            m5.append(joined_names)\n",
    "            m5i.append(joined_names[0])\n",
    "\n",
    "            if len(name_split[-1]) > 1:\n",
    "                ln.append(name_split[-1])\n",
    "                lni.append(name_split[-1][0])\n",
    "            else:\n",
    "                lni.append(name_split[-1][0])\n",
    "            \n",
    "\n",
    "    return [list(set(x)) for x in [fn,fni,m1,m1i,m2,m2i,m3,m3i,m4,m4i,m5,m5i,ln,lni]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46639b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_block_vs_block(block_1_names_list, block_2_names_list):\n",
    "    \n",
    "    # check first names\n",
    "    first_check, _ = match_block_names(block_1_names_list[0], block_1_names_list[1], block_2_names_list[0], \n",
    "                                    block_2_names_list[1])\n",
    "    # print(f\"FIRST {first_check}\")\n",
    "    \n",
    "    if first_check:\n",
    "        last_check, _ = match_block_names(block_1_names_list[-2], block_1_names_list[-1], block_2_names_list[-2], \n",
    "                                           block_2_names_list[-1])\n",
    "        # print(f\"LAST {last_check}\")\n",
    "        if last_check:\n",
    "            m1_check, more_to_go = match_block_names(block_1_names_list[2], block_1_names_list[3], block_2_names_list[2], \n",
    "                                           block_2_names_list[3])\n",
    "            if m1_check:\n",
    "                if not more_to_go:\n",
    "                    return 1\n",
    "                m2_check, more_to_go = match_block_names(block_1_names_list[4], block_1_names_list[5], block_2_names_list[4], \n",
    "                                                block_2_names_list[5])\n",
    "                \n",
    "                if m2_check:\n",
    "                    if not more_to_go:\n",
    "                        return 1\n",
    "                    m3_check, more_to_go = match_block_names(block_1_names_list[6], block_1_names_list[7], block_2_names_list[6], \n",
    "                                                block_2_names_list[7])\n",
    "                    if m3_check:\n",
    "                        if not more_to_go:\n",
    "                            return 1\n",
    "                        m4_check, more_to_go = match_block_names(block_1_names_list[8], block_1_names_list[8], block_2_names_list[8], \n",
    "                                                block_2_names_list[9])\n",
    "                        if m4_check:\n",
    "                            if not more_to_go:\n",
    "                                return 1\n",
    "                            m5_check, _ = match_block_names(block_1_names_list[10], block_1_names_list[11], block_2_names_list[10], \n",
    "                                                block_2_names_list[11])\n",
    "                            if m5_check:\n",
    "                                return 1\n",
    "                            else:\n",
    "                                return 0\n",
    "                        else:\n",
    "                            return 0\n",
    "                    else:\n",
    "                        return 0\n",
    "                else:\n",
    "                    return 0\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        swap_check = check_if_last_name_swapped_to_front_creates_match(block_1_names_list, block_2_names_list)\n",
    "        # print(f\"SWAP {swap_check}\")\n",
    "        if swap_check:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "def get_name_from_name_list(name_list):\n",
    "    name = []\n",
    "    for i in range(0,12,2):\n",
    "        if name_list[i]:\n",
    "            name.append(name_list[i][0])\n",
    "        elif name_list[i+1]:\n",
    "            name.append(name_list[i+1][0])\n",
    "        else:\n",
    "            break\n",
    "    if name_list[-2]:\n",
    "        name.append(name_list[-2][0])\n",
    "    elif name_list[-1]:\n",
    "        name.append(name_list[-1][0])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return name\n",
    "        \n",
    "def check_if_last_name_swapped_to_front_creates_match(block_1, block_2):\n",
    "    name_1 = get_name_from_name_list(block_1)\n",
    "    if len(name_1) != 2:\n",
    "        return False\n",
    "    else:\n",
    "        name_2 = get_name_from_name_list(block_2)\n",
    "        if len(name_2)==2:\n",
    "            if \" \".join(name_1) == \" \".join(name_2[-1:] + name_2[:-1]):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "def match_block_names(block_1_names, block_1_initials, block_2_names, block_2_initials):\n",
    "    if block_1_names and block_2_names:\n",
    "        if any(x in block_1_names for x in block_2_names):\n",
    "            return True, True\n",
    "        else:\n",
    "            return False, True\n",
    "    elif block_1_names and not block_2_names:\n",
    "        if block_2_initials:\n",
    "            if any(x in block_1_initials for x in block_2_initials):\n",
    "                return True, True\n",
    "            else:\n",
    "                return False, True\n",
    "        else:\n",
    "            return True, True\n",
    "    elif not block_1_names and block_2_names:\n",
    "        if block_1_initials:\n",
    "            if any(x in block_1_initials for x in block_2_initials):\n",
    "                return True, True\n",
    "            else:\n",
    "                return False, True\n",
    "        else:\n",
    "            return True, True\n",
    "    elif block_1_initials and block_2_initials:\n",
    "        if any(x in block_1_initials for x in block_2_initials):\n",
    "            return True, True\n",
    "        else:\n",
    "            return False, True\n",
    "    else:\n",
    "        return True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022ee8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_sim_between_name_cols(col_1, col_2):\n",
    "    emb_1 = emb_model.encode(col_1)\n",
    "    emb_2 = emb_model.encode(col_2)\n",
    "\n",
    "    return [round(cosine_similarity(emb_1i.reshape(1, -1), emb_2i.reshape(1, -1))[0][0], 4)\n",
    "            for emb_1i,emb_2i in zip(emb_1, emb_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c741de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_from_S3(filename, data_type = 'train'):\n",
    "    cols_to_get = ['sample_type'] + cols_for_pred\n",
    "    df = pd.read_parquet(filename, columns=cols_to_get)\n",
    "    \n",
    "    df['author_1_name_list'] = df['author_1'].apply(get_name_match_list)\n",
    "    df['author_2_name_list'] = df['author_2'].apply(get_name_match_list)\n",
    "    df['author_name_check'] = df.apply(lambda x: check_block_vs_block(x.author_1_name_list, x.author_2_name_list), \n",
    "                                       axis=1)\n",
    "    df['exact_match'] = df.apply(lambda x: 1 if x.author_1==x.author_2 else 0, axis=1)\n",
    "    df['name_1_len'] = df['author_1'].apply(len)\n",
    "    df['name_1_spaces'] = df['author_1'].apply(lambda x: len(x.split(\" \")))\n",
    "    df['exact_match_len'] = df['exact_match'] * df['name_1_len']\n",
    "    df['exact_match_spaces'] = df['exact_match'] * df['name_1_spaces']\n",
    "    \n",
    "    df['inst_per'] = df['inst_match'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    df['concepts_per'] = (df['concepts_match']/df['concepts_sum']).apply(lambda x: round(x, 4))\n",
    "    df['concepts_shorter_per'] = (df['concepts_shorter_match']/df['concepts_shorter_sum']).apply(lambda x: \n",
    "                                                                                                 round(x, 4))\n",
    "    df['concepts_shortest_per'] = (df['concepts_shortest_match']/df['concepts_shortest_sum']).apply(lambda x: \n",
    "                                                                                                 round(x, 4))\n",
    "    df['coauthors_per'] = (df['coauthors_match']/df['coauthors_sum']).apply(lambda x: round(x, 4))\n",
    "    df['coauthors_shorter_per'] = (df['coauthors_shorter_match']/df['coauthors_shorter_sum']).apply(lambda x: \n",
    "                                                                                                 round(x, 4))\n",
    "    df['citation_per'] = (df['citation_match']/df['citation_sum']).apply(lambda x: round(x, 4))\n",
    "    \n",
    "    print(df.shape)\n",
    "    \n",
    "    df['label'] = df['sample_type'].apply(lambda x: 1 if x=='positive' else 0)\n",
    "    \n",
    "    if data_type == 'train':\n",
    "        df = df[df['author_name_check']==1].copy()\n",
    "        print(df.shape)\n",
    "    \n",
    "    \n",
    "    df_label_val_counts = df['label'].value_counts()\n",
    "    num_to_sample = min(df_label_val_counts)\n",
    "    \n",
    "    if data_type == 'train':\n",
    "        first_df = df[df['label']==0].copy().sample(ceil(num_to_sample))\n",
    "        second_df = df[df['label']==1].copy().sample(ceil(num_to_sample*0.4))\n",
    "        df = pd.concat([first_df, second_df], axis=0).sample(int(num_to_sample*1.4))\n",
    "    \n",
    "    return df.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_df = get_dataframe_from_S3(\"<path-to-training-data>\", 'train')\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a530a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = get_dataframe_from_S3(\"<path-to-validation-data>\", 'val')\n",
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_dataframe_from_S3(\"<path-to-testing-data>\", 'test')\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet(\"./datasets_to_share/disambiguator_training_data/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c06d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_parquet(\"./datasets_to_share/disambiguator_training_data/val.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b013d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_parquet(\"./datasets_to_share/disambiguator_training_data/test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afee145",
   "metadata": {},
   "source": [
    "### Training XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bfbe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccbe8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target='label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d6292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_results = pd.read_csv('test_results.csv')\n",
    "def modelfit(alg, dtrain, dtest, predictors, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        xgtest = xgb.DMatrix(dtest[predictors].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0],eval_metric='auc')\n",
    "    \n",
    "    # Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain[target])\n",
    "        \n",
    "    # Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob))\n",
    "    print(f'Precision (Train): {metrics.average_precision_score(dtrain[target], dtrain_predprob)}')\n",
    "    \n",
    "    # Predict on testing data:\n",
    "    dtest_pred_prob = alg.predict_proba(dtest[predictors])[:,1]\n",
    "    print('AUC Score (Test): %f' % metrics.roc_auc_score(dtest[target], dtest_pred_prob))\n",
    "    print(f'Precision (Test): {metrics.average_precision_score(dtest[target], dtest_pred_prob)}')\n",
    "                \n",
    "    print(\"\")\n",
    "    \n",
    "    return alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38534e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors = [x for x in train_df.columns if x not in [target, 'sample_type','author_1', 'insts_1', \n",
    "#                                                        'concepts_1', 'coauthors_1', 'author_2', 'insts_2', \n",
    "#                                                        'concepts_2', 'coauthors_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3325b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictors = ['emb_sim', 'inst_match','inst_1_len','inst_2_len','inst_sum', 'inst_per', 'concepts_1_len',\n",
    "                  'concepts_2_len','concepts_match', 'concepts_sum', 'concepts_per',\n",
    "                  'concepts_shorter_1_len','concepts_shorter_2_len','concepts_shorter_match', 'concepts_shorter_sum',\n",
    "                  'concepts_shorter_per', 'concepts_shortest_1_len','concepts_shortest_2_len'\n",
    "                  'concepts_shortest_match','concepts_shortest_sum','concepts_shortest_per','coauthors_1_len',\n",
    "                  'coauthors_2_len','coauthors_match','coauthors_sum', 'coauthors_per','citation_match',\n",
    "                  'citation_1_len','citation_2_len','citation_sum','citation_per','citation_work_match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03400685",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['inst_per','concepts_shorter_per', 'coauthors_shorter_per','exact_match_len','exact_match_spaces','citation_per','citation_work_match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6a8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[predictors].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea75ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    "    'max_depth': [15, 40, 65],\n",
    "    'min_child_weight': [1, 4, 8],\n",
    "    'colsample_bytree':[0.4, 0.6, 0.8], \n",
    "    'n_estimators': [50, 90, 200],\n",
    "    'learning_rate':[0.1, 0.2]\n",
    "    \n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "                                        min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    "                       param_grid = param_test1, scoring='average_precision',n_jobs=4, cv=5)\n",
    "gsearch1.fit(train_df[predictors],train_df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a8631",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823560ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_params_,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcccc9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    "            learning_rate =0.2,\n",
    "            n_estimators=100,\n",
    "            max_depth=12,\n",
    "            min_child_weight=1,\n",
    "            gamma=0.0,\n",
    "            subsample=0.7,\n",
    "            colsample_bytree=0.9,\n",
    "            objective= 'binary:logistic',\n",
    "            nthread=4,\n",
    "            scale_pos_weight=1,\n",
    "            seed=27)\n",
    "trained_model = modelfit(xgb1, train_df, val_df, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0345efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(predictors, trained_model.feature_importances_.tolist()):\n",
    "    print(f\"{i} - {j}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb66cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"<local-path-to-model>/Disambiguator.pkl\", \"wb\") as f:\n",
    "    pickle.dump(trained_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65bc800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
